{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data used to perform the analysis\n",
    "\n",
    "The precidency of Donald J. Trump began at noon EST (17:00 UTC) on January 20, 2017 when he was inaugurated as the 45th president of the United States, and will com to an end the on January 20, 2021 as he ultimately lost the 2020 presidential election to Joe Biden. It is not far fetched to say it has been bizare precidency compared to the most recent precidencies. \n",
    "\n",
    "It feels like America has been splitted in two the suporters of Trump and those agianst him - Repulicans agianst Democrats. In this project we wanted to explore if our hypothesis of polarization can be seen or rejected by analyzing the Congress of United States behavoir on the social media Twitter including the infamous Twitter account manged by Donald J. Trump. The idea was to analyze the congress tweets from the time of the 45th precidency to explore potential polarization.\n",
    "\n",
    "With access to the Twitter API it is only possible to exctract the most reason 3200 tweets from a given account (3200 tweet do not go far back for many american polticians). However, Twitter's Terms of Service do allow for datasets of tweets ID's to be distributed to third parties (not the full JSON). Luckily we found two sources that keep tweet id open very related to our project and one sources that stored the full length tweets of Donald Trump namely:\n",
    "\n",
    "* **115th U.S. Congress Tweet Ids:**\n",
    "    A open dataset with 2,041,399 tweets from the Twitter accounts of members of the 115th U.S. Congress collected in the period of January 27, 2017 and January 2, 2019. The dataset consists two files of interest namely\n",
    "    * `senators-1.txt` that contains tweet ids for Seneators\n",
    "    * `representatives-1.txt` that contains tweet ids for Representatives\n",
    "    *Littman, Justin, 2017, \"115th U.S. Congress Tweet Ids\", https://doi.org/10.7910/DVN/UIVHQR, Harvard Dataverse, V5.*\n",
    "\n",
    "* **116th U.S. Congress Tweet Ids**\n",
    "    A open dataset with 2,817,747 tweets from the Twitter accounts of members of the 116th U.S. Congress collected in the period of January 27, 2019 and May 7, 2020.  The dataset consists two files of interest namely\n",
    "    * `Senators: congress116-senate-ids.txt` that contains tweet ids for Seneators\n",
    "    * `Representatives: congress116-house-ids.txt` that contains tweet ids for Representatives  * Wrubel, Laura; Kerchner, Daniel, 2020, \"116th U.S. Congress Tweet Ids\", https://doi.org/10.7910/DVN/MBOJNS, Harvard Dataverse*\n",
    "\n",
    "* **Trump Twitter Archive**\n",
    "    A site dedicated to scrape every single tweet from Donald J. Trump. Here we downloaded all tweets in the periods of January 27, 2017 and January 2, 2019 and January 27, 2019 and May 7, 2020. https://www.thetrumparchive.com/\n",
    "\n",
    "Examing the Harvard Dataverse we discovered that polticians in congress can have number of profiles for instance a private profile, a profile associated with work in congress and campaign profile. Unfortunally the data also contains a large number of random profiles. Moreover there is tweet dateing as far back as 2008. Furthermore it was not listed what party the account where associated with. However, we found a list of congress memebers with their party association, whether they act as Senator or Represenative and, most important for the project, their twitter profile (if they have an account the vast majority has). That meant rather than dealing with multiple accounts for the same congress member or including random account we would only consider one account per congress member. Two different sources for the 115 and 116 congress have been utilized for this namely\n",
    "\n",
    "* 116. Congress twitter info: (website) https://triagecancer.org/congressional-social-media \n",
    "* 115. Congress twitter info : (PDF) https://www.sciencecoalition.org/wp-content/uploads/2018/09/115th-Congress-Twitter-Handles.pdf  \n",
    "\n",
    "The politicans listed in these to documents as well as Donald Trump are the twitter profiles that ones that will considered. The information needs to scraped as the format is HTML and PDF respectively.\n",
    "\n",
    "# Handeling the Data\n",
    "This notebook will explain how the above described data was exstracted and preprocessed. The easist way to re-create the data is to clone the github repository: https://github.com/MikkelGroenning/social_graph and setup the corrosponding conda environment and run this Notebook.  The notebook consist of four parts and one smaller part devoted to extrating Trump tweets id (part 0). So in total:\n",
    "* **Part 0: Exstract Trump Tweet IDs**\n",
    "    Here the tweet id are exstacted from the tweets made publicly by https://www.thetrumparchive.com/\n",
    "\n",
    "* **Part 1: Hydrate Tweets**\n",
    "    In this part all the tweet ids from Harvard data archive as well as Trumps tweet id, are hydrated. I.e. the ids are turned back into tweets with metadata. \n",
    "\n",
    "* **Part 2: Getting Congress Twitter Account**\n",
    "    Here a pandas data frame is constructed from information scraped from the PDF describing the 115 Congress memebers twitter accounts, and the HTML site describing the 116 Congress Twitter info.\n",
    "\n",
    "* **Part 3: Clean-up of Harward Data**\n",
    "    The Harvard data archive needs to be cleaned prior to analsis as it contains\n",
    "    * Data prior to January 27, 2017\n",
    "    * Duplicates\n",
    "    * Many random profiles \n",
    "    * Remove random/duplicate twitter accounts\n",
    "    \n",
    "* **Part 4: Preprocess the twitter data**\n",
    "    Many tweets contains links, emojies etc that makes it difficult to perform natural language processing on. In this part the tweets are preprocessed such that they can be used for our analysis.\n",
    "    \n",
    "    \n",
    "Below can all the library dependicies be read. Note the import of functions from our own module `src`. The source code for these functions can be read on our github repository https://github.com/MikkelGroenning/02805_social_graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import camelot\n",
    "import tweepy\n",
    "import tqdm\n",
    "from src.data.trump_tweet_ids import get_trump_tweet_ids\n",
    "from src.data.hydrate import hydrate_tweets\n",
    "from src.tools.twitter_api_credentials import api_key, api_secret_key, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file twitter_api_credentials.py can't be found in out Github repository as it contains classified information about our creditiels to the Twitter API. To recreate the dataset one needs to access the Twitter API through developer account is needed. Such an account can be requested at https://developer.twitter.com/en/apply-for-access typically one is granted access instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "except tweepy.TweepError:\n",
    "    print('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Exstract Trump Tweet IDs\n",
    "As the site Trump Twitter Achive (https://www.thetrumparchive.com/) store Donald Trump's tweets in a different format than how it typically exstracted from Twitter-API we exstracted the tweet id from this sources and stored them in the file `trump_id.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trump_tweets1 = pd.read_csv('../Data/raw/tweets/trump_tweets_1st.csv')  \n",
    "df_trump_tweets2 = pd.read_csv('../Data/raw/tweets/trump_tweets_2nd.csv')\n",
    "df_trump = pd.concat([df_trump_tweets1, df_trump_tweets2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11326 tweet ids saved\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../Data/raw/tweets/trump_id.txt\"\n",
    "get_trump_tweet_ids(df_trump, filepath)"
   ]
  },
  {
   "source": [
    "### Hydrate Tweets\n",
    "The process of turning tweet ID's into actual tweets with metadata is called *hydration* and requires Twitter delopper account. In the below cell we load all twitter ids obtained from Harward Data Archive and Trump Twitter Archive."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hydrate Tweets\n",
    "The process of turning tweet ID's into actual tweets with metadata is called *hydration* and requires Twitter delopper account. In the below cell we load all twitter ids obtained from Harward Data Archive and Trump Twitter Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4870472\n"
     ]
    }
   ],
   "source": [
    "representatives115 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/representatives115.txt\", dtype=int\n",
    ")\n",
    "representatives116 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/representatives116.txt\", dtype=int\n",
    ")\n",
    "senators115 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/senators115.txt\", dtype=int\n",
    ")\n",
    "senators116 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/senators116.txt\", dtype=int\n",
    ")\n",
    "trump = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/trump_id.txt\", dtype=int\n",
    ")\n",
    "congress = np.concatenate([representatives115, representatives116, senators115, senators116, trump])\n",
    "print(len(congress))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatted into array of tweet id consist of 4.8 millions ID. All these tweet are now hydrated with the function `hydrate_tweets` located in src/data folder in our reposortiry. Note running the cell below take $24 \\pm 6$ hours as the twitter API set limits to how much can be exstracted. More info about rate limits can be found at https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Data/interim/congress.pkl\"\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "hydrate_tweets(\n",
    "    tweet_ids=congress,\n",
    "    filepath=filepath,\n",
    "    api = api\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Getting Congress Twitter Account\n",
    "In this part a pandas data frame will generated with each members congress member's name State, Type (Reprensative, sSnator, POTUS), Name, Party. This part cosist of three subparts:\n",
    "* **Part 2.1: 116<sup>th</sup>** Here the desired data frame for 116 congress will be scraped\n",
    "* **Part 2.2: 115<sup>th</sup>** Here the desired data frame for 115 congress will be scraped\n",
    "* **Part 2.3: Merge data** Here the different congress data frame will be merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: 116<sup>th</sup> congress\n",
    "\n",
    "First the twitter handles for the 116<sup>th</sup> congress will be extracted using [this](https://triagecancer.org/congressional-social-media) source. The choice of source comes from the fact that the Twitter handle as well as the party is desired.\n",
    "\n",
    "`BeautifulSoup` is used to extract the HTML table from the webpage (that has been downloaded to allow for offline work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "with open('../Data/Raw/116_congress_twitter.html') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Find table\n",
    "table = soup.find('table', attrs={'id':\"footable_16836\"})\n",
    "\n",
    "# Extract data row wise from table\n",
    "l = []\n",
    "for tr in table.findAll('tr'):\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "# Make the data into a Pandas data frame and drop irrelevant columns\n",
    "Data116 = pd.DataFrame(l[1:], columns = [header.getText() for header in table.findAll('th')]).drop(columns = ['Name Links', 'Twitter Links', 'Instagram', 'Facebook Page', 'Facebook'])\n",
    "\n",
    "# Ensure that the type of politician is alligned\n",
    "rename_chamber = {'U.S. Representative': 'Representative', 'U.S. Senator': 'Senator'}\n",
    "Data116 = Data116.replace(rename_chamber).rename(columns = {'Chamber of Congress': 'Type'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set the state is given as well as congressional district. This is fixed using regex strings as shown below. Moreover the \"@\" are removed from the Twitter handles as the Twitter API does not need it. The vancant positions in Congress are also disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>R</td>\n",
       "      <td>SenShelby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Doug Jones</td>\n",
       "      <td>D</td>\n",
       "      <td>DougJones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Byrne, Bradley</td>\n",
       "      <td>R</td>\n",
       "      <td>RepByrne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Roby, Martha</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMarthaRoby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Rogers, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMikeRogersAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Tiffany, Thomas</td>\n",
       "      <td>R</td>\n",
       "      <td>TomTiffanyWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Gallagher, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>MikeforWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Enzi, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>SenatorEnzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Barrasso, John</td>\n",
       "      <td>R</td>\n",
       "      <td>SenJohnBarrasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>WY</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Cheney, Liz</td>\n",
       "      <td>R</td>\n",
       "      <td>Liz_Cheney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State            Type             Name Party          Twitter\n",
       "0      AL         Senator   Richard Shelby     R        SenShelby\n",
       "1      AL         Senator       Doug Jones     D        DougJones\n",
       "2      AL  Representative   Byrne, Bradley     R         RepByrne\n",
       "3      AL  Representative     Roby, Martha     R    RepMarthaRoby\n",
       "4      AL  Representative     Rogers, Mike     R  RepMikeRogersAL\n",
       "..    ...             ...              ...   ...              ...\n",
       "536    WI  Representative  Tiffany, Thomas     R     TomTiffanyWI\n",
       "537    WI  Representative  Gallagher, Mike     R        MikeforWI\n",
       "538    WY         Senator       Enzi, Mike     R      SenatorEnzi\n",
       "539    WY         Senator   Barrasso, John     R  SenJohnBarrasso\n",
       "540    WY  Representative      Cheney, Liz     R       Liz_Cheney\n",
       "\n",
       "[537 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All states abbreviations\n",
    "us_state_abbrev = {\n",
    "    r'Alabama.*': 'AL',\n",
    "    r'Alaska.*': 'AK',\n",
    "    r'American Samoa.*': 'AS',\n",
    "    r'Arizona.*': 'AZ',\n",
    "    r'Arkansas.*': 'AR',\n",
    "    r'California.*': 'CA',\n",
    "    r'Colorado.*': 'CO',\n",
    "    r'Connecticut.*': 'CT',\n",
    "    r'Delaware.*': 'DE',\n",
    "    r'District of Columbia.*': 'DC',\n",
    "    r'Florida.*': 'FL',\n",
    "    r'Georgia.*': 'GA',\n",
    "    r'Guam.*': 'GU',\n",
    "    r'Hawaii.*': 'HI',\n",
    "    r'Idaho.*': 'ID',\n",
    "    r'Illinois.*': 'IL',\n",
    "    r'Indiana.*': 'IN',\n",
    "    r'Iowa.*': 'IA',\n",
    "    r'Kansas.*': 'KS',\n",
    "    r'Kentucky.*': 'KY',\n",
    "    r'Louisiana.*': 'LA',\n",
    "    r'Maine.*': 'ME',\n",
    "    r'Maryland.*': 'MD',\n",
    "    r'Massachusetts.*': 'MA',\n",
    "    r'Michigan.*': 'MI',\n",
    "    r'Minnesota.*': 'MN',\n",
    "    r'Mississippi.*': 'MS',\n",
    "    r'Missouri.*': 'MO',\n",
    "    r'Montana.*': 'MT',\n",
    "    r'Nebraska.*': 'NE',\n",
    "    r'Nevada.*': 'NV',\n",
    "    r'New Hampshire.*': 'NH',\n",
    "    r'New Jersey.*': 'NJ',\n",
    "    r'New Mexico.*': 'NM',\n",
    "    r'New York.*': 'NY',\n",
    "    r'North Carolina.*': 'NC',\n",
    "    r'North Dakota.*': 'ND',\n",
    "    r'Northern Mariana Islands.*':'MP',\n",
    "    r'Ohio.*': 'OH',\n",
    "    r'Oklahoma.*': 'OK',\n",
    "    r'Oregon.*': 'OR',\n",
    "    r'Pennsylvania.*': 'PA',\n",
    "    r'Puerto Rico.*': 'PR',\n",
    "    r'Rhode Island.*': 'RI',\n",
    "    r'South Carolina.*': 'SC',\n",
    "    r'South Dakota.*': 'SD',\n",
    "    r'Tennessee.*': 'TN',\n",
    "    r'Texas.*': 'TX',\n",
    "    r'Utah.*': 'UT',\n",
    "    r'Vermont.*': 'VT',\n",
    "    r'Virgin Islands.*': 'VI',\n",
    "    r'Virginia.*': 'VA',\n",
    "    r'Washington.*': 'WA',\n",
    "    r'West V.*': 'WV', # Written in different ways\n",
    "    r'Wisconsin.*': 'WI',\n",
    "    r'Wyoming.*': 'WY'\n",
    "}\n",
    "\n",
    "# Convert states to two letter abbreviations\n",
    "Data116['State'] = Data116['State'].replace(regex = us_state_abbrev)\n",
    "\n",
    "# Remove @\n",
    "Data116 = Data116.replace(regex = {r'^@': ''})\n",
    "\n",
    "# Remove vacant positions\n",
    "Data116 = Data116[Data116.Name != \"Vacant\"]\n",
    "\n",
    "# Look at the data\n",
    "Data116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also seen that there are an inconsistency in the ways the names are written. This is changed so all names are written with the first name first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data116['Name'] = [name[1][1:]+ \" \" +name[0] if len(name) == 2 else name[0] for name in [name.replace(u'\\xa0', u'').split(',') for name in Data116.Name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: 115<sup>th</sup> congress\n",
    "\n",
    "Now we move onto the 115th congress. This is data stored in a pdf.table, so for this the `camelot` library is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "file115 = '../Data/Raw/115_congress_twitter.pdf'\n",
    "\n",
    "# Read table across all pages\n",
    "tables = camelot.read_pdf(file115, pages = 'all')\n",
    "\n",
    "# Convert data to pandas data frame\n",
    "Data115 = pd.DataFrame(np.concatenate([d.df.drop(0).values for d in tables]), columns=tables[0].df.iloc[0]).drop(columns = \"District\")\n",
    "\n",
    "# Align chamber name with the 116 data\n",
    "rename_chamber = {'Rep.': 'Representative', 'Sen.': 'Senator'}\n",
    "Data115 = Data115.replace(rename_chamber)\n",
    "\n",
    "# Align name with the 116 data and store it in one column\n",
    "Data115[\"Name\"] = Data115[\"First Name\"] + \" \" + Data115[\"Last Name\"]\n",
    "Data115 = Data115.drop(columns = [\"First Name\", \"Last Name\"])\n",
    "\n",
    "# Align columns name with the 116 data\n",
    "Data115 = Data115.rename(columns = {'Title': 'Type', \"Twitter Handle\": \"Twitter\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Merge data\n",
    "\n",
    "Now the two datasets are merged. Here we need to take duplicate acounts into account which accounts for reelections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data set\n",
    "Data_Full = Data115.append(Data116, ignore_index = True)\n",
    "\n",
    "# Get shape\n",
    "Data_Full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below is Twitter display name exstracted with twitter API for full data. This is done as the full name does not always match the Twitter Display Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1072it [16:04,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "to_remove = []\n",
    "twitter_display_name = []\n",
    "for index, handle in tqdm.tqdm(enumerate(Data_Full.Twitter)):\n",
    "    try:\n",
    "        u=api.get_user(handle)\n",
    "    except Exception:\n",
    "        to_remove.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop(index=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra duplicate from AS\n",
    "Data_Full = Data_Full[Data_Full.Twitter != 'RepTomPrice']\n",
    "\n",
    "# Drop closed users\n",
    "Data_Full = Data_Full[~Data_Full.Name.isin(['Aumua Radewages', 'Madeleine Bordallo', 'Elizabeth Esty'])]\n",
    "\n",
    "# Fix Eric\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Erik Paulsen\"].index,\"Twitter\"] = \"ErikPaulsen\"\n",
    "\n",
    "# Fix Bobby\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Bobby Scott\"].index,\"Twitter\"] = \"BobbyScott\"\n",
    "\n",
    "# Fix Dave\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Dave Reichert'].index,\"Twitter\"] = \"TeamReichert\"\n",
    "\n",
    "# Fix Lindsey\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Lindsey Graham'].index,\"Twitter\"] = \"LindseyGrahamSC\"\n",
    "\n",
    "# Darin's name\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"arin LaHood\"].index,\"Name\"] = \"Darin LaHood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Twitter\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Name\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the President"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.append({'State': None, 'Party': 'R', 'Type': 'POTUS', 'Twitter': 'realDonaldTrump', 'Name': 'Donald J. Trump', 'twitter_display_name': 'Donald J. Trump'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_display_name = [api.get_user(handle).name for handle in Data_Full.Twitter]\n",
    "Data_Full['twitter_display_name'] = twitter_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full.to_csv('../Data/Processed/Twitter_Handles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Clean-up of Harward Data\n",
    "In this part the Harward data is cleaned such that:\n",
    "* It only contains tweets from account from `Data_Full`. \n",
    "* There is only tweets from the two periods of January 27, 2017 to January 2, and 2019 January 27, 2019 to May 7, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_pickle('../Data/Interim/congress.pkl')\n",
    "twitter_handles = pd.read_table('../Data/Processed/Twitter_Handles_updated.csv', sep = ',')\n",
    "\n",
    "s1 = set(twitter_handles['twitter_display_name'])\n",
    "s2 = set(congress.user_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below can non-overlapping twitter profile between the dataframe containing tweets from congress and the data frame created in part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'US Rep Brendan Boyle',\n 'ããŸããŸã®ã‘ã„ãŸã‚',\n 'lulur',\n 'ğ“‘ğ“±ğ“¾ğ“¿ğ“ªğ“·ğ“®ğ“¼ğ“± ğ”€ğ“ªğ“»ğ“ªğ“·',\n 'Fran Givens',\n 'Ma yuyu',\n 'ğŸ’',\n 'Cesar AndresğŸ’™ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§ğŸğŸ‡¨ğŸ‡±',\n 'Sarisa06',\n 'Martha McSally for U.S. Senate',\n 'Hank Johnson',\n 'Du_BalÃ£o',\n 'Bill Flores',\n 'â™¡ğ˜„ğ—¶ğ—¸ğ—®â·â™¡',\n 'JesÃºs â€œChuyâ€ GarcÃ­a',\n 'Rike',\n 'MatthewBroome',\n 'ExequielğŸ‡¦ğŸ‡·ğŸ‡¨ğŸ‡±ğŸ‡µğŸ‡¾',\n 'Rep. Mike Kelly',\n 'Cryptbuzz',\n 'Thomas Parker',\n 'Idy',\n 'O patrÃ£o ğŸ¤¡',\n 'á´®á´± á´á´á´á´â· ğŸ‘‘ || Ê™ÉªÊŸÊŸÊ™á´á´€Ê€á´… #1 á´€Ê€á´›Éªêœ±á´›êœ±',\n 'Dr. jawaher \\U0001f90d',\n 'Vallenato FM',\n 'Ancor',\n 'Adrian',\n 'Dan Sullivan',\n 'S H I M A A â¤ï¸',\n 'HollyHill',\n 'PameğŸ¤ª',\n 'Cecy Badillo',\n 'alice â™¥',\n 'Mark E. Green, MD',\n 'mari',\n 'diağŸ ì•š',\n 'Steven Palazzo',\n 'Djeni ğŸ¦‹',\n 'Dave Loebsack for Iowa',\n 'ğŸ’ T',\n 'Deb',\n 'Duarte & Partner',\n 'Ron Johnson',\n 'Eric Swalwell',\n 'TeaDay 10/17',\n 'ChingasX',\n 'Nicola Vietri',\n 'á´®á´±sisiâ·ğŸ¦‹',\n 'Donna E. Shalala',\n 'à®¨à®¿à®²à®¾à®©à®¿',\n 'DBSstudent927',\n \"â€¢ Mina D'IemanjÃ¡ â€¢\",\n 'Jennifer Wexton',\n 'Donna',\n 'luana',\n 'Rep. Paul Mitchell',\n 'HurricaneğŸŒŒBady',\n 'Spies Santana ğŸ•Š',\n 'ğŸš',\n 'Greg Steube',\n 'Afnan',\n 'Jorge Rey',\n 'Xochitl Torres Small',\n 'TagaağŸ‡¸ğŸ‡³',\n 'G',\n 'Mighty JJ',\n 'Ayanfe Obilana',\n 'Pat Roberts',\n 'Mukomana Weku Ruwa',\n 'Peter por la AutonomÃ­a',\n 'Declan Shalvey',\n '#freeeromzğŸ§–ğŸ¿\\u200dâ™€ï¸#ENDSARS #ENDSARSNOW',\n 'Matheus âœ  âœŠğŸ¾',\n 'HJã€½ï¸',\n 'Lisa Henney',\n 'Ñ•Ñ‚Ñ”Î½Ñ”',\n 'âœ¨á¶œÊ³á¶ ',\n 'Meggilyweggily',\n 'manu #SantaDose',\n 'SWRV é‡‘ VITOğŸğŸ',\n 'Derek Kilmer',\n 'Narcissistic Abuse Rehab / #MenHealing',\n 'Carolina',\n 'Frank LoBiondo',\n 'ãƒãƒˆãƒ ã‚®',\n 'ãƒã‚œã‚¯ãƒãƒ³(Â´ï½¥_ï½¥`)',\n 'Dt.AFNAN~',\n 'Susan Brooks',\n 'ã‚Šã‚…ã†ã˜ã‚“',\n 'kiarra.ğŸ‘¨ğŸ¿\\u200dğŸ¦°',\n 'Juliana Guedes',\n 'DanielağŸŒ™\\U0001fa90',\n 'ğŸ‡¹ğŸ‡·ğŸ‡¹ğŸ‡·ğŸ‡¹ğŸ‡·ğŸ‡¹ğŸ‡·ğŸ‡¹ğŸ‡·ğŸ‡¹ğŸ‡·',\n 'Paul Shoulberg',\n 'ãƒ‘ãƒãƒ§ï¼ˆÂ´-`\\u3000ï¼‰',\n 'ãŸã“ã‘ã¤',\n 'Anthony Brindisi',\n 'Mathys',\n 'calvin',\n 'â€˜ keeğŸ¥³',\n 'Ruben J. Kihuen',\n 'bangtan & army',\n 'necoko@ã­ã“ã“ã“ã“ã“ã“ã“ã“ã“ã“',\n 'Qui voilÃ -je?',\n 'suquinho',\n 'Bob Casey Jr.',\n 'samantha davis',\n 'Yuichi WATANABE',\n 'Thu PhÆ°Æ¡ng _ ì•„ë¶€â¤â¤',\n 'Nicole Locke',\n 'ã±ã¿ã‚…ã‚Œãƒ³ã‚´',\n 'Gregg in FL',\n 'B',\n 'ÎŸÎ»Î¬ ÎšÎ±Î»Î¬',\n 'Jason Crow',\n 'â˜† multilisting.su â˜†',\n 'Darren Soto',\n 'sabzq',\n 'Eco Goth',\n 'Tom Malinowski',\n 'GCSE MEMES ğŸ©',\n 'Deise ğŸ’Ÿ',\n '#TonyCardenasğŸ‡ºğŸ‡¸',\n 'NatÃ¡lia',\n 'Rep. Ilhan Omar',\n 'James Angus',\n 'å¤èŠ½@ãƒã‚±ãƒ¢ãƒ³ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼å…¼å¯©ç¥è€…',\n \"Oleg's bizarre adventure\",\n 'MaJo',\n 'Salvador RamÃ­rez',\n 'â¯ğ˜½ğ–¨ğ–«ğ–«ğ–¸.',\n 'Andy',\n 'barry laughton',\n 'Ø³Ù„ÛŒÙ…Ø§Ù† Ø´Ø§Û',\n 'á´›Ê€Éªs || ğ’‡ğ’ğ’ğ’Œğ’ğ’ğ’“ğ’†â·',\n 'Pete Aguilar',\n 'LuisPÃ©',\n 'yasmeenğŸŒ»',\n 'nath â¤',\n \"Ø®Ù€Ù„ÙŠÙ„ ğŸ’™'\",\n 'Team GT - Friends of Glenn Thompson',\n 'Edickson Pantoja',\n 'Ù…Ù†Ø®ÙØ¶ Ù†Ø¬Ø¯',\n 'Rick Larsen',\n 'Ï‰asskuu ã‹¡',\n 'lovelyluckylife',\n 'Cami VargasğŸŸ',\n 'spooky isa ğŸƒ',\n 'Taylor',\n 'â†¬linna OUT DE TRETAS',\n 'Scott Peters',\n 'Pieter',\n 'é¢¨æ­»',\n 'Greg Stanton',\n 'Tim Waddy',\n 'Adam',\n 'pupuce',\n 'Î±lÕªÎ±Õ²Î±âš˜',\n '@JasonSmithMO',\n 'Ivanilda Maria',\n 'Emir Diblan',\n 'Ron Estes',\n 'oceano Ã© pacifico eu nÃ£oâ™ï¸',\n 'Fresh Me Up',\n 'Archive: Senator McCaskill Office',\n 'ğ•°ğ–‘ğ•®ğ–ğ–‰â™‘',\n 'Mike Fitzpatrick',\n 'Barry Loudermilk',\n 'William McCarren',\n 'ãªã‚‹',\n 'Eric Sturrock',\n 'Hope Dreemurr',\n 'Colin Allred',\n 'Arno Roa',\n 'Senator Hawley Press Office',\n 'bebecita ğŸ’—',\n 'Mohammad Ameer Hamza â',\n 'Sean Duffy',\n 'Ù',\n 'Dr. Ralph Abraham',\n 'Lloyd Smucker',\n 'piera bianchi',\n 'Javi',\n 'Ù„Ù€ Ù…Ø­Ù…Ø¯ Ø§Ø­Ù…Ø¯ Ø§Ù„Ù…Ø²Ø±ÙˆØ¹ÙŠ',\n 'Anja Hoffmann',\n 'Rep. Jamie Raskin',\n 'US Rep. Al Lawson Jr',\n 'Lucy McBath',\n 'ace ğŸ’‰',\n 'aiko',\n 'NomhleğŸŒ¹',\n 'Vero',\n 'Valen',\n 'Harriet Mearns-Thomas',\n 'robtherichğŸ˜ˆ',\n 'LizğŸ±',\n 'Marsha Blackburn',\n 'Don Young',\n 'Mr.GettaBagğŸ’°',\n 'stan',\n 'Jason Chaffetz',\n 'SuviğŸŒŸ',\n 'Dick Durbin',\n 'Rep. Donald McEachin',\n 'A L E',\n 'jord',\n 'Flyest Anakin',\n 'lil spanish girl ğŸ’',\n 'dawn',\n 'Nso.1391',\n 'á´®á´±J.Yiingâ·',\n 'Sean Casten',\n 'maybe: aliya',\n 'ğ´ğ‘›ğ‘ğŸ¦•',\n 'TNC',\n 'lampiÃ£o niilista',\n 'ğ¦ğšğ§ğ¨ğ§ | ğ¯ğ¢ğ¥ğ® ğœğšğ¬ğ­ ğšğ­ ğğ¢ğšğ¡ğŸ”',\n 'Team McCaul',\n 'Brian Schatz',\n 'William Monastero',\n 'CostaParda',\n 'Rob Miech',\n 'Kristaps',\n 'Crossroads Church',\n 'Catalina B.',\n 'MLiâœŠğŸ¿',\n 'scarlett x',\n 'Alexander Thorvaldsen',\n 'Almutairy~',\n 'Cleaver For Congress ğŸ—³',\n 'Johnny Roy',\n 'Cindy Axne',\n 'Sai Krish',\n 'Susie Lee',\n 'Dr. Kim Schrier',\n 'Massilva Dihya',\n 'UmyoğŸ°ìš°ë¬˜',\n \"Fay 's secrets&lies\",\n 'Yvette D. Clarke for Congress',\n 'Tom Carper',\n 'Pete Visclosky',\n 'Freedom_isnâ€™t_Free_2020_Beyond',\n 'Haifa Saleh',\n 'ã‚·ãƒ¥ãƒ³ã€‚',\n 'Wear a damn mask',\n 'Gossip8.com',\n 'siemprecarelocoymarginado',\n 'Tim Burchett',\n 'ì…˜ë§ˆì˜ ì†Œì‹¤',\n 'ğ•¬ğ–—ğ–ğ–Šğ–‘ ğ•½ğ–ğ–‡ğ–Šğ–ğ–—ğ–”',\n 'Team Reichert',\n 'Noha â™ŠğŸ‡ªğŸ‡¬',\n 'Gil Cisneros',\n 'Son_of_Chief',\n 'Ronaldo Almeida',\n 'Nica Justo',\n 'tony lukasavage',\n 'Florent Villain Nguyen',\n 'Test Account1',\n 'ÙØ±ÙÙˆØ´ ÙˆÙ‡ÙØ±ÙØ´Ùƒ Ù…Ø¹Ø§ÙŠØ§ ÙŠØ§ Ø¨Ø¶ÙŠÙ†',\n 'Thom Tillis',\n 'David Cicilline',\n 'âœ ğ•®ğ–ğ–“ğ–™ğ–ğ–†âœ ',\n 'Mark James',\n 'Ğ’ÑĞµĞ²Ğ¾Ğ»Ğ¾Ğ´ Ğ¥Ñ€Ğ°Ğ±Ñ€Ğ¾Ğ²',\n 'Bayram Trust',\n 'Mitt Romney',\n 'Governor Kristi Noem',\n 'Rep. John Rutherford',\n 'Luther Strange',\n 'Mike',\n 'é’å«',\n 'STEPHENMAKESART',\n 'Rep. Pete Olson',\n 'NMWriter',\n 'prin',\n 'Jordan Wilson',\n 'Fitness Nutrition',\n 'Viktoriaâ£ï¸',\n 'Mark Warner HQ',\n 'Rak paz paz paz',\n 'Jean Simon jsimon73',\n 'TJ Cox',\n 'noahà¼„',\n 'Rob Wittman',\n 'Bob Latta',\n 'Louise Slaughter',\n 'Dave Trott',\n 'nursya',\n 'Spencer Shroyer',\n 'ã‚­ã‚­',\n 'Mark Acklin âœ­',\n 'Congressman Jeff Van Drew',\n 'Alfonsina ğŸ’›',\n 'âœŒğŸ¿âœŒğŸ¿',\n 'Congressman Dan Bishop',\n 'kuwait',\n 'Lynda Garibaldi',\n 'ğŸ„ â—¤ğ“¥ğ‘œğ“‡ğ“‰ğ‘’ğ“â—¥ PaDoRu ğŸ„',\n 'Fede Raspanti',\n 'Kelly Armstrong',\n 'Taata NyunyuğŸ‡ºğŸ‡¬',\n 'La Huerta Patria ğŸ‡»ğŸ‡ª VEN VAMOS JUNTğŸŒ±S',\n 'Rep. Brian Mast',\n 'Ginny',\n 'Camila Cabello',\n 'ğ”–ğ”ğ”Ÿğ”¯ğ”¦ğ”«ğ”â',\n 'Guy Reschenthaler',\n 'Josh Harder',\n 'ğŸ–¤',\n 'Chris Stewart',\n 'RoadRunner',\n 'ğŸ¤¸ğŸ»\\u200dâ™€ï¸',\n 'PuffPlug',\n '4ever_Crissy â™¥',\n 'Exella',\n 'shaiâ¤ï¸',\n 'McHenry for Congress',\n 'U.S. Senator Bill Cassidy, M.D.',\n 'å¤§åœŸè±†',\n 'John Rutherford',\n 'flor de lopez',\n 'Turgut Gunturk',\n 'Doug Collins',\n 'Iramar Truffi',\n 'saissaâà¼„Breath of Love à¼„',\n 'yamini-gadani',\n 'ğƒğˆğğğ˜ğ’ğˆğ”ğ’ ğŸ–¤',\n 'Rep. Dan Bishop',\n 'Analyteek Marketing Agency',\n 'anni',\n 'Adam Smith',\n 'Eshoo for Congress',\n 'yusuf abdu',\n 'Adonis Otogari',\n 'Jim Risch for US Senate',\n 'Juan Sanchez',\n 'Cenk KeleÅŸ',\n \"â‚± â™¡'s ê‡™ê‹¬ê‹Šê‹¬\",\n 'â„³ğ‘ğ‘›ğ‘¢ğŸ‘» is a ğ’»ğ’¶ğ’¾ğ“ğ“Šğ“‡ğ‘’',\n 'mariaâ˜†',\n 'Higgins for Congress',\n 'FAHAD ALBSHAIER',\n 'AngÃ©lica Serrano-RomÃ¡n ğŸ‡µğŸ‡·',\n 'Fortu ğŸ¦‹',\n '#EllağŸ¤¸ğŸ¾\\u200dâ™€ï¸ #LeonaMoodğŸ¦ğŸ‡©ğŸ‡´ #SuDoloresâ¤',\n 'Laura Catalina',\n 'Louise',\n 'valent',\n 'Carlos Curbelo',\n 'é¡¾ä¼Ÿè¶…',\n 'Anastasia',\n 'L.I.B. Pimp',\n \"Kevin Biersack's\",\n 'Big sad',\n 'Brett Guthrie',\n 'Haley Stevens',\n 'ã¯ã‚„ã—ã‚ˆã†ã„ã¡',\n 'Karen Lievisse Adriaanse',\n 'John McCain',\n 'Megan',\n 'Joe Neguse',\n 'Dean Phillips ğŸ‡ºğŸ‡¸',\n 'jo',\n 'ğ‘†ğ´ğµğ´á´®á´± \\u200eâœœ',\n 'PG',\n 'Gina',\n 'Debbie Dingell',\n 'Eccentric Goddess',\n \"Ta'Niya Breedlove\",\n 'Armas Shercas',\n 'Alex.',\n 'Casey',\n 'The House',\n 'ğ˜¦ğ˜­ğ˜£ğ˜¢ ğ˜­ğ˜¢ğ˜»ğ˜° ğ˜¯ğ˜¢ğ˜·ğ˜ªğ˜¥ğ˜¦Ã±ğ˜°',\n 'Ãlvaro RodrÃ­guez',\n 'crevette',\n 'Billy Long',\n 'Salva',\n 'Jim Bridenstine',\n 'Jethalal Gathha',\n 'dragovic',\n 'Maguida SchmittğŸ‡§ğŸ‡·ğŸ‡§ğŸ‡·',\n 'Frank Pallone, Jr.',\n 'ğ•°ğ•· à¼—',\n 'â€  Maruri - Sama  â€ ',\n 'Lorenzo ğŸ”±',\n 'Mario Pandemio',\n 'RÃ¡dio TrÃ¢nsito',\n 'Mike Simpson',\n 'Abi',\n 'áµ‰áµáµğŸ¹',\n 'ğŸ¦‹zahira ~ #BLACKLIVESMATTERâœ¨',\n 'MJ Hegar',\n 'Mum Z',\n 'Rand Paul',\n 'Brad Sherman',\n 'ğŸ’› Josi_HG ğŸŒº',\n 'ã‚‰ã¹ã‚“ï¼šãƒãƒ«ãƒã‚¯å®Ÿæ³S&S',\n 'Tom Tiffany',\n 'wes',\n '#REDDEVILFORLIFE',\n 'John Boozman',\n '50.050 JOTA Ã© meu vereador',\n 'Nate McMurray for Congress 2020',\n 'William Timmons',\n 'MaGbedu',\n 'Susan Wild',\n 'Senator Mike Braun',\n 'Anarchosatanist',\n 'Dusty Johnson',\n 'M. Fazal Elahi',\n 'Jeff Duncan',\n 'gorilla grip',\n 'Mike Gallagher',\n 'Todd Young',\n 'Henrique',\n 'Dennis Ross',\n 'Kendra Horn',\n 'ğ•­ğ–†ğ–“ğ–“ğ–†ğ–ğŸ',\n 'Rep. Arrington',\n 'seyyar diplomat',\n 'Pat Toomey',\n 'DanoRivi',\n 'Lester B. Pearson HS',\n 'Pluton Ver B Nero',\n 'Rep. Stephanie Murphy',\n 'andrea',\n 'Ø§Ø³Ù…Ø±',\n 'WEJDAN',\n 'josÃ© urach ğŸ’™vote45ğŸ’™',\n 'The Golden God',\n 'itzzzğŸ”¥',\n 'Sen. Cory Booker',\n 'Michael X',\n 'Solari Josyane',\n 'Scottsbluff Schools',\n 'David Trone',\n 'Yossarian',\n 'á´µá´ºá¶ á´¬á´¹á´¼áµË¢á´·á´µá´° ğŸ‡µğŸ‡ªğŸ‡ºğŸ‡¸',\n 'John Sarbanes',\n 'Staybridge Liverpool',\n 'ãƒ¨ãƒ³ã‚¹èªéŒ²bot',\n 'Nico',\n 'KimyA the Challenger',\n 'Tomas: Today',\n 'cisne lojana',\n 'Sara',\n 'Senar',\n 'KaylağŸ§œğŸ¿\\u200dâ™€ï¸',\n 'Joe Cunningham',\n 'Luiza Linhares',\n 'Mike (Wear a Mask) Thompson',\n 'Brian Fitzpatrick',\n 'Ted Lieu',\n 'isabella â˜€ï¸',\n 'Soy Pedro Pedro',\n 'Ted Writes TWS',\n 'Glenn Grothman',\n 'ğ•„ğ•–ğ••ğ•šğ•¤ğ•¤ğ• ğ•Ÿ',\n 'Mark O. Stack',\n 'Debbie Mucarsel-Powell',\n 'Franky Lavender',\n 'Shelley âŒeyer',\n 'Ø£Ø­Ù…Ø¯',\n 'ã‚ã‚‰ã—ã¹é•·è€…ï¼ ãƒšãƒ³ã‚¿',\n 'Rep Andy Biggs',\n 'Lizzie Pannill Fletcher',\n 'Rep. Val Demings',\n 't. ğŸ§šğŸ½\\u200dâ™€ï¸',\n 'Soy La Cacho',\n 'THE CHOSEN ONE',\n 'Fleur',\n 'Rep. Ruben J. Kihuen',\n 'yngri',\n 'kam the ğŸŒ™ witch',\n '(((Jerry Nadler)))',\n 'Wayne Waldo',\n 'Lauren Underwood',\n 'Wyden for Oregon',\n 'ğŸ˜´',\n 'closed',\n 'Jose Antonio',\n 'Imran',\n 'Rep. Mike Gallagher',\n 'joona',\n 'à¸à¸µà¸à¸µà¸à¸µà¸à¸´à¹Šà¸ğŸš¨',\n 'TXIPAYA',\n 'Fnm9',\n 'Walberg for Congress',\n 'B.B.',\n 'Just Dave',\n 'Ratio Strain',\n 'Jim Clyburn SC-06',\n 'tNr',\n 'ğŸ§˜ğŸ½\\u200dâ™€ï¸ Lula',\n 'Stevie Chalmers',\n 'Ù…Ù‘',\n 'U.S. Senator Al Franken',\n 'Gerry Connolly',\n 'viniá¶œÊ³á¶ ',\n 'Ingrid Adjes',\n 'Andres Zubelzu',\n 'à¹à¸«à¸‡à¸°',\n 'HayağŸŒ¸',\n 'jul',\n 'hugh dancy supremacy',\n 'Mark Pocan',\n 'ĞĞ»ĞµĞºÑĞ°Ğ½Ğ´Ñ€Ğ¾Ğ²Ğ° ĞĞ½Ğ¶ĞµĞ»Ğ°',\n 'Steve Watkins',\n 'Kerie505â­ï¸â­ï¸â­ï¸',\n 'Rhonda@Tide Girl',\n 'SerenaCockayneJones',\n 'Stephen F. Lynch',\n 'Ivy',\n 'emmaa',\n 'VJ RishellğŸŒ¹ğŸ“âœŒğŸ’–ğŸ––',\n 'luci',\n 'mskathleenquinn',\n 'Farah.',\n 'Team Joe Wilson',\n 'âœ¨',\n 'John Kennedy',\n 'Certified Lover Boy',\n 'lizaâ·',\n 'Dan Lipinski',\n 'deusa do olimpo',\n 'ğŸ‡»ğŸ‡ªÂ¡Â¡AZUCA!! y Â¡Â¡OLÃ‰!!ğŸ‡ªğŸ‡¸',\n 'Serwi ğŸ¦‹',\n 'Kathy Castor',\n 'Rep. Salud Carbajal',\n 'Maria Cantwell',\n 'Denver Lee Riggleman III',\n 'Ø§Ù„ØªÙ‚ÙˆÙ‰ Ø§Ù„Ù‡Ø¬Ø±',\n 'SiteSpect',\n 'Tatan Steven',\n 'Meurig Jones',\n 'Ross Spano',\n 'KYT0305',\n 'Jared Golden for Congress',\n 'Deborah Allen',\n 'REI DA AMERICA ğŸ‡·ğŸ‡º',\n 'á´®á´± sâ·',\n 'Scott',\n 'Ø¬Ù‡Ù†Ù…ÙŠØ©',\n 'Ryan Wooledge',\n 'King for Congress',\n 'kuddy',\n 'Gwen S. Moore',\n 'Joe Manchin',\n 'Hieronymus Bosch Butt Music',\n 'neta da bruma de Avalon',\n 'Faizaan \\u2066ÙÛŒØ¶Ø§Ù†',\n 'Richard. ğŸ¥‹ğŸ¤´ğŸ¾',\n 'â˜»',\n 'Pete King',\n 'JavierluisME',\n 'Sen. Jeff Van Drew',\n 'Chip Roy',\n 'Mac Thornberry',\n 'Ann Kirkpatrick',\n 'alice',\n 'Ana Gallardo',\n 'Tulsi Gabbard ğŸŒº',\n 'Fino Filipino',\n 'ğŸ§œğŸ½\\u200dâ™€ï¸',\n \"T.F.ğŸ˜ WeThePeopleLet'sRollğŸ‡ºğŸ‡¸\",\n 'Greg Vorse TV',\n 'Almirante Brown con Emilio',\n '#..â·',\n 'Susie Bradford',\n 'Hemiâœ¨',\n 'Isa Rey',\n 'ã¿ã†ã‚‰',\n 'Lozzzzz',\n 'Sen. Kirsten Gillibrand',\n 'asia',\n 'nikolai nikolov',\n \"Rep. Tom O'Halleran\",\n 'JoshYourBro',\n 'Rep. Pramila Jayapal',\n 'Ø§Ù„Ø³Ø§Ù…Ø¨Ùˆ',\n '_sxmeyra',\n 'Bradley Byrne',\n 'kurashiyu muhammad',\n '.... à´…à´‚à´œàµ .....\\uf8ff',\n 'Lois Frankel',\n 'Madeleine Dean',\n 'En fin, la hipocresÃ­a',\n 'Chris Van Hollen',\n 'Emilio MC MUTUAL',\n 'Anthony Gonzalez',\n 'memneon',\n 'Erotic Pics',\n 'Taheem C.',\n \"Candy'nin Kendisi\",\n 'j',\n 'Peony..ğŸŒ¼',\n 'the good soldier',\n 'AgnÃ¨s ğŸŒ',\n 'Ace',\n 'Ø¬Ù',\n 'ğŸ”—Ù…Ù€Ø³Ù€ØªÙ€Ø´Ù€Ø§Ø± Ø¨Ù€Ø§Ù„Ù€ØµÙ€Ø¯Ù…Ù€Ø§ØªğŸ”—',\n 'Vicky Hartzler',\n 'c â˜† f ã…¡ milktea',\n 'A',\n 'Russ Fulcher',\n 'Francesco Calandrino',\n 'ãƒ’ãƒ©',\n 'Ton GRH',\n 'Bruno CapelÃ£o',\n 'Tina Smith',\n 'hiuru åˆ',\n 'Justin Willis',\n 'Â¹â¹â°â·',\n 'Anthony G. Brown',\n 'uÄŸur kotan',\n 'barbara peake wise',\n 'Steny Hoyer',\n 'M@vocab',\n 'ğŸ™',\n 'Joe Crowley',\n 'Marcelo Galeano',\n 'ğ–ğ–—ğ–”ğ–“ ğ–ğ–Šğ–†ğ–‰',\n 'prodigy04',\n 'Whitehouse for Senate',\n 'pitanga',\n 'Sen. Maggie Hassan',\n 'JOB,S&NEWS',\n 'â˜ ï¸',\n 'Veronica Escobar',\n 'Elizabeth Esty',\n 'Rep. Katie Hill',\n 'nathanaliel',\n 'Karen Bass',\n 'HellbabyğŸ§Ÿ\\u200dâ™‚ï¸\\U0001fa78',\n 'â¨ŸCheoleoleâ¨Ÿ ğ—›ğ—¢ğ— ğ—˜;ğ—¥ğ—¨ğ—¡ |ğˆğã…¡ğğ”ğ“|',\n 'Michael F.Q. San Nicolas',\n 'amor da sua vida',\n 'ğŸŒ¸',\n 'Ben McAdams',\n 'Southernbelledonna',\n 'And The Tweet Goes On',\n 'Tiquito',\n 'fausto jarrÃ­n z',\n 'KiMinSeoKookâ·á´®á´± ğŸ‡µğŸ‡°',\n 'DiiiiiğŸ§šğŸ¾\\u200dâ™‚ï¸',\n 'Anacleto Panceto ğŸ³ï¸\\u200dğŸŒˆ',\n 'Wilfredo Briceno',\n 'TC#BJKTURK-ER',\n 'William PeÃ±a',\n 'shakanuys',\n 'Marcin WalasğŸ’¯ğŸ‡µğŸ‡± â€ ',\n 'Marcia L. Fudge',\n 'Barcelona :-)',\n 'Tom Bombie',\n 'Carolyn B. Maloney',\n 'Sen. Grassley Press',\n 'Lori Trahan',\n 'Siya Alex Junior',\n 'Councilor of Hammanskraal',\n 'Steve Chabot',\n 'Keith Murdoch',\n '#NiUnaMenos ğŸ’š',\n 'Darrell S',\n 'Belu Musante',\n 'ã‚³ã‚«ã‚³ãƒ¼ãƒ©',\n 'sorry guys .',\n 'Paul Mitchell',\n 'Dwight Evans',\n 'aqil iman',\n 'Mazie Hirono',\n 'JB',\n 'ğ“µğ“²ğ“¼ğ“¼ â™”',\n 'jÏ…lÎ¹a âš¡ | will see 5sos',\n 'John Conyers, Jr.',\n 'Ù…ÙˆÚ©Øª Ø¨Ø±',\n 'ÙÙŠØµÙ„ Ø§Ù„Ø±Ø­ÙŠÙ„ÙŠ',\n '\\U0001f90dğŸ°III',\n 'Merceditas #SoyDel41',\n 'ã‚¸ã‚§ãƒ‹ãƒ•ã‚¡ãƒ¼ã‚ˆã†ã“',\n 'Ben Sasse',\n 'Sama .',\n 'Michael Guest',\n 'Â©Â®',\n 'yerr',\n 'Naveenarunkumar',\n 'Ted Deutch',\n \"mt'áµ—Ê³áµ‰áµÂ²Â²ğŸ¤´\",\n 'sunsetâ·',\n 'â‚â‚‚â‚‡â· â†º blm + acab *',\n 'ØµØ­ÙŠÙØ© Ø§Ù„Ø¥Ø±Ø§Ø¯Ø©',\n 'Sophie',\n 'LangevinForCongress',\n 'Mike Bost',\n 'Ø§Ø¨Ùˆ Ø®Ø§Ù„Ø¯',\n 'AdriÃ¡n',\n 'Gary Peters',\n 'Rick Rigazio',\n 'Ken Buck',\n 'à¤¬-\\u200cTATA',\n 'Antonio Delgado',\n 'Ğ•Ğ»ĞµĞ½Ğ°',\n 'Mike Turner',\n 'Jiwon',\n 'Lamar Alexander',\n 'Alexandria Ocasio-Cortez',\n 'Ben Marshall',\n 'ç–æ¥½bot',\n 'Congressman Fred Keller',\n 'Elise Stefanik',\n 'mama bear for biden',\n 'carolinE',\n 'Ronny Rojas R..',\n 'leah á´®á´±â·',\n 'Princess Luna',\n 'uosuÉ¥oÉ¾ snÇÉppÉÉ¥Ê‡',\n 'mamÃ£e do OtÃ¡vio ğŸ’™ğŸ¤°',\n 'Marco á¶œÊ³á¶ ',\n 'Liveoak',\n 'Bertieâ€™s Pet Kraken',\n 'Clara McKenzie',\n 'Scott White',\n 'Paul Gosar',\n 'nath',\n 'ğŸ˜‰ğŸ˜¥ğŸ¥‘oanamp11',\n 'JÃºlia Mussauer',\n 'Jayce',\n 'vineet kapoor',\n 'Ø¨Ù† ÙŠØ±Ø¨Ù‡ Ø±Ù…Ø¸Ø§Ù†',\n 'Debbie Stabenow',\n 'Ä°smail HakkÄ± Kavurma',\n 'Marc Veasey',\n 'Kelly',\n 'Max Rose',\n 'JN',\n 'ColliesandCakesğŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n 'Charlie Dent',\n 'Bruce Westerman',\n 'Debbie Wasserman Schultz',\n 'Kevin Brady for Congress',\n 'Jack Mehoff',\n 'kasey \\U0001fa81 nj luvr â·',\n 'frida',\n 'Mary Gay Scanlon',\n 'Jon Tester',\n 'FÄ“ngshuÇ',\n 'ã®ã‚“ğŸ',\n 'a noiva',\n 'Î ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î¿ Î‘ÏÎºÎ±Î´Î¹Î±ÎºÏŒ Î¼Ï€Î¿Ï…Î¼ÎµÏÎ¯ÏƒÏ„Î¹ÎºÎ¿ 2019 Ï„Î¿ ÎœÎ±ÏÎ¹Î½Î¬ÎºÎ¹',\n 'John Larson',\n 'Andy Levin',\n 'Mohamed Ahmed \\u2066ğŸ‡©ğŸ‡ª\\u2069',\n 'Mike Levin',\n 'El SeÃ±or Bendecido',\n 'ğŸ–¤ director jeon jungkook',\n 'hip_hop_jam',\n 'Rep. Devin Nunes',\n 'LuÃ­sa',\n 'Rep. RaÃºl Grijalva',\n 'ğšŠğš—ğšŠ',\n 'ğ–‰ ğ–š ğ–‰ ğ–† \\uf8ff',\n 'Jerry Woods',\n 'ã‚‰ã´ã­ã‚‹ï¼ èŠ582',\n 'James Kraft',\n 'ãƒ™ãƒ³ãƒªãƒ¼ç”²åºœè¥¿åº—',\n 'ğ”ğ”Ÿğ”¯ğ”¦ğ”©ğŸ’§',\n 'Marcela Colcer',\n 'Muadâ€™Yke',\n 'Dr. Ami Bera',\n 'Rep. Lloyd Doggett',\n 'P I S A J ğŸŒº E L F',\n '#Constituyente-Independiente',\n 'vivianağŸ§šğŸ»',\n 'ã¨ã‚‚ãŒã‚†ã',\n 'Matsui for Congress',\n 'Robb_714',\n 'Paul Ryan',\n 'Igor Miras ğŸ‡¾ğŸ‡ª',\n 'lindsğŸ¦‹âœ°ğŸ',\n 'Denis Liriano',\n 'MÃ¼nzâ˜­asten #675',\n 'Maria',\n 'Rep. Ro Khanna',\n 'paige',\n 'Polly Pocket',\n 'ExeMPLaR',\n 'ãŒã‚ã²â­ï¸',\n 'Mike Rogers Campaign',\n 'Sen. Murphy Office',\n 'Transparencia Activa',\n 'Rep. Jimmy Panetta',\n 'Lisa',\n 'T.F. Pfyl',\n 'Mthokozisi Mpanza',\n 'Maurin',\n 'Natalia ğŸš€',\n 'JSBot',\n 'Samuel',\n 'alliâ· | extremely inactive',\n 'Heraâ€™s final Nerve',\n 'Andy Sugden',\n 'Bobby Scott',\n 'Buddy',\n 'John Johnson',\n 'Jimmie. Leafs, No Racists! Proud Algonquin Family',\n 'Joe Kennedy III',\n 'Dutch for Congress',\n 'Dan Meuser',\n 'F L O R A H. Z.',\n 'Tim Ryan',\n 'Deb Fischer',\n 'Dana Lee Hagstrom',\n 'ğŸ¦‹ğ“¶ğ“²ğ“¬ğ“ªğ“®ğ“µğ“ªğŸ¦‹',\n 'Yvette Clarke',\n 'nicoleâ·',\n 'h.r.',\n 'Rayane Freitas',\n 'Nzo ğŸŒ‘',\n 'kâ· â™¡BLM',\n 'Alex Mooney',\n 'Bishop for Congress',\n 'Zoe Lofgren',\n 'Capito for WV',\n 'Swiss TrIck',\n 'Umarell',\n 'Lewis Wyatt',\n 'Samantha',\n 'Rod Poblete',\n '[ë™ê²°] í•˜ë‡¬ğŸ‘',\n 'Blake Farenthold',\n 'milind shah',\n 'á´á´€Ê€ ğŸ’•',\n 'Kayman',\n 'Bob Flynn',\n 'commonsense4all',\n 'Rep Josh Gottheimer',\n 'Jim McGovern',\n 'ğŸ‡¹ğŸ‡· isaSNDC ğŸ‡¹ğŸ‡·',\n 'Ted Cruz',\n 'Ø´Ù',\n 'ludovic louvel',\n 'Annie Kuster',\n 'DOIXDÃŠ /EX MC 2D ğŸ”¥',\n 'ğ˜£ğ˜¶ğ˜£ğ˜¶ âœ¯',\n 'sams',\n 'JoÃ£o Vitor Oliveira',\n 'ChartMill',\n 'ğŸ‡ºğŸ‡¸ğŸ…ğŸ»ğŸ¤¶ğŸ»â˜ƒï¸ğŸ‘‘ğŸˆğŸ¥¡ğŸ¤ŸğŸ»#GoPats #6xsChamps #Jasam',\n 'Alexamarie ğŸ’–',\n 'Will Hurd',\n 'Van Taylor',\n 'ğŸ’™Å pelağŸ’™',\n 'Bill Keating',\n 'TOotağŸ•ŠğŸ’™',\n 'Andy Kim',\n 'ãƒ¦ãƒ¼ãƒãƒ¼ãƒˆãƒ¬ãƒƒãƒ•ã‚§ãƒ³bot',\n 'MOVEDğŸ“Œ',\n 'Rep. Clay Higgins',\n 'Derick04kt1772 á´¬á´°á´º \\u200f',\n 'Geovani Hazan',\n 'Hefeydd ğŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n 'sham masri',\n 'E',\n 'Ahmedzaghloul',\n 'Rotexx_bangingğŸ‡³ğŸ‡¬â˜',\n 'EnZo',\n 'G/ols',\n 'EMR',\n 'Dan Kildee',\n 'ğŸ’… Me',\n 'ğŸƒğŸ‘ºâ˜ ï¸Conservative Policiesâ˜ ï¸ğŸ‘ºğŸƒ',\n 'Chris Pappas',\n 'KODAWARISAN',\n 'YaKulT',\n 'grimcity',\n 'MauroyğŸ‡¯ğŸ‡²',\n 'FatManNickğŸ¤™ğŸ¾â„¢ï¸',\n 'Kindle The Reaper',\n 'moved.',\n 'Mike Garcia',\n 'Ø·',\n 'Pat Tiberi',\n 'Amr Khalifa',\n 'Noumu4',\n 'Solus, ACB Devotee',\n 'ãƒãƒ©ã‚¦ã‚§ã‚¤',\n 'Michael Cloud',\n 'Ayanna Pressley',\n 'Trucker World',\n 'love',\n 'Fred Upton',\n 'Alex MacLeod',\n 'LuLu boom boom Roche',\n 'Inmaculada GonzÃ¡lez',\n 'Gino Hawley',\n 'Macieldasilva23ğŸ”‚100% SDV',\n 'GeschÃ¤ftsfÃ¼hrer der BRD GmbH',\n 'Seth Moulton',\n 'BMK',\n 'Senator Amy Klobuchar',\n 'Archive: Tom Graves',\n 'Derrick.',\n 'Leader McConnell',\n 'SorAlex',\n 'â„âœ¨ireneâœ¨â„',\n 'John Carter',\n 'Jimmy Gomez',\n 'andrÃ© rougier',\n 'SÃ©rgio Campos',\n 'Mike Johnson',\n 'Big Hoss',\n 'ERO SENNIN æ²¹',\n 'WealthÃ©',\n 'ğŸ‡®ğŸ‡³à¤…à¤‚à¤œà¤²à¥€ à¤à¤¾ğŸ‡®ğŸ‡³ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¤ªà¥à¤°à¥‡à¤®à¥€ ğŸš© #à¤œà¤¯_à¤¶à¥à¤°à¥€à¤°à¤¾à¤® ğŸ•‰ï¸',\n 'sergio',\n 'æ¶²ä½“ãƒ©ã‚¤ãƒ ',\n 'AmiCerv',\n 'Rep. David Kustoff',\n 'YooY',\n 'JÃ¶rg Stephan',\n 'juliğŸ‡¦ğŸ‡·',\n 'maixee',\n 'Dan Crenshaw',\n 'Ø¬ÙˆØ¯ ğŸ¼.',\n 'Î— Î˜Î·ÏÎ¹Î¿Î´Î±Î¼Î¬ÏƒÏ„ÏÎ¹Î±',\n 'Duende',\n 'Vani',\n 'Ryan Zinke',\n 'Shanrock',\n 'Dr. Raul Ruiz',\n 'Bartosz Lisowski',\n 'Ben Cardin',\n 'Eduarda Limberger',\n 'UsaÙ…ah ğŸŒ»',\n 'RJ',\n 'Don Bacon',\n 'Ariamehr',\n 'Mikie Sherrill',\n 'KennShiestyğŸ¦„',\n 'Steve Womack',\n 'KimyDee',\n 'migiã€‡',\n 'Houdi ğŸ‘\\u200dğŸ—¨',\n 'Marcelino MuÃ±oz',\n 'Fofa Mahmoud',\n 'kie',\n 'Ù…ÙˆØ³Ù‰ Ø§Ù„ÙÙŠÙÙŠ',\n 'rl powell',\n 'Kiapan ğŸ—½ğŸ•',\n 'Carlos Magdaleno',\n 'mako',\n 'Mâ™¥ï¸ISÃ‰S',\n 'John Thune',\n 'Tom Udall Press',\n 'BLACK LIVES MATTER. (Darwin thought so too)',\n 'Elaine Luria',\n 'Katerina Pantelides',\n 'Tom Price',\n 'Andrea_98',\n 'Senator Thad Cochran',\n 'Ø§Ø­Ù…Ø¯Ø±Ø´ÙˆØ§Ù† Ø§Ø­Ù…Ø¯',\n 'Norma Torres',\n 'YWCA Cambridge, MA',\n 'Darealest Hoodini',\n 'á´®á´± ğš’ğšœ ğšŒğš˜ğš–ğš’ğš—ğšğŸ”®âœ¨',\n 'b âœ¶',\n 'king kerr',\n \"Schrodinger's Cat ğŸ‡®ğŸ‡³\",\n 'Nydia M VelÃ¡zquez',\n 'David Schweikert',\n 'Kweisi Mfume',\n 'Aerandir',\n 'Congresswoman Tenney',\n 'Rep. Liz Cheney',\n 'Ì¶YÌ¶Ì¶OÌ¶Ì¶UÌ¶Ì¶SÌ¶Ì¶UÌ¶Ì¶FÌ¶ Ì¶CÌ¶Ì¶OÌ¶Ì¶bÌ¶Ì¶RÌ¶Ì¶AÌ¶ ğŸ',\n 'Darcy McRae ğŸ›¡ğŸ•ŠğŸ›¡ğŸ•ŠğŸ›¡ğŸ•Š#Archewell Army',\n 'calamitous intent',\n 'â™‘',\n 'Katie Golding ğŸ FEARLESS is OUT NOW',\n '.',\n 'Carlitos Colomes',\n 'SmamağŸ“',\n 'Cathy McMorris Rodgers',\n 'Ron Kind',\n 'Barbara Lee',\n 'Maria Isabel',\n 'Kevin Cramer',\n 'Ø£Ù…Ù„ ğŸ¦‹',\n 'Jeff Merkley',\n 'ğ“…“',\n 'RodneyfrtğŸ‡§ğŸ‡·',\n 'Le360',\n 'ğ“˜ ğ“ªğ“¶ ğ”€ğ“¸ğ“·ğ“°',\n 'Roger Wicker',\n 'grey â™ˆï¸ EST',\n 'Greg Walden',\n 'F4MJaz ğŸ’…ğŸ¾',\n 'ğŸ“Šá´›Êœá´€á´› Ò“á´Ê€á´‡x É¢á´á´…á´…á´‡ss âœ¨',\n ...}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "s1 ^ s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure tweets only comes from people that twitter handles exist for. \n",
    "congress = congress[congress.user_name.isin(s1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the periods from Harward:\n",
    "mask = (\n",
    "    #January 27, 2017 and January 2, 2019 \n",
    "    (congress.created_at > '2017-1-27 00:00:00') & (congress.created_at < '2019-1-2 00:00:00')\n",
    "    | \n",
    "    #January 27, 2019 and May 7, 2020 \n",
    "    (congress.created_at > '2019-1-27 00:00:00') & (congress.created_at < '2020-5-7 00:00:00')\n",
    ")\n",
    "congress = congress[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = congress.drop_duplicates(keep='first')\n",
    "congress = congress.sort_values(by='created_at')\n",
    "congress = congress.reset_index(drop=True)\n",
    "congress.to_pickle(\"../data/interim/congress_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1650398"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(congress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleanup results in $4,870,472-1,650,398 = 3,220,074$ less tweets than the orginal data. These tweet ids are saved such as they can be shared online with concent of Twitter. That will make it lot faster to hydrate the tweets of interest of one want to re-create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1650398 tweet ids saved.\n"
    }
   ],
   "source": [
    "# Extract the tweets ids and convert them to integers\n",
    "ids = list(congress.id.astype(int).values)\n",
    "\n",
    "filepath = \"../Data/raw/tweets/Cleaned_tweet_id.txt\"\n",
    "with open(filepath, 'w') as output:\n",
    "    for row in ids:\n",
    "        output.write(str(row) + '\\n')\n",
    "\n",
    "    print(f'{len(ids)} tweet ids saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1 Shortcut to exstract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe with tweets of from congress after cleanup contain about 33 % rows of data prior to clean-up. This means it data can be hydrated much quick. Running the cell below take $8 \\pm 6$ hours and creates the same `congress` data frame as had it been cleaned up. \n",
    "The cleaned tweet id can be found at 'http://groenning.net/data/Cleaned_tweet_id.txt' as the file is too large to be on Github. The below cell make sure that the list is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "uurl = 'http://groenning.net/data/Cleaned_tweet_id.txt'\n",
    "file_name = \"../Data/Raw/Tweets/Cleaned_tweet_id.txt\"\n",
    "\n",
    "response = urlopen(uurl)\n",
    "data = response.read()      # a `bytes` object\n",
    "text = data.decode('utf-8') # convert from bytes object\n",
    "\n",
    "with urlopen(uurl) as response, open(file_name, 'wb') as out_file:\n",
    "    data = response.read() # a `bytes` object\n",
    "    out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_tweet_id = np.loadtxt(\"../Data/Raw/Tweets/Cleaned_tweet_id.txt\", dtype=int)\n",
    "filepath = \"../Data/interim/congress_cleaned.pkl\"\n",
    "\n",
    "hydrate_tweets(\n",
    "    tweet_ids=congress_tweet_id,\n",
    "    filepath=filepath,\n",
    "    api = api\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Preprocess the twitter data\n",
    "In this part the cleaned tweet will processed such that the text is suited for natural language processing. The cells below do the following\n",
    "* Convert HTML tags to UTF8 symbol and text\n",
    "* Make all tweet lowercase\n",
    "* Remove all links from tweets\n",
    "* Replace all unicode whitespace with normal space\n",
    "* Remove all unknown charcters and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_pickle('../Data/Interim/congress_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = \"@#\"\n",
    "character_set = {\n",
    "    \"characters\": \"abcdefghijklmnopqrstuvwxyz0123456789\" + special_characters,\n",
    "    \"space\": \" \",\n",
    "}\n",
    "alphabet = \"\".join(character_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_links = re.compile(\"http\\S+\")\n",
    "regex_whitespace = re.compile(\"[\\s|-]+\")\n",
    "regex_unknown = re.compile(f\"[^{alphabet}]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_html_tags = {\n",
    "    \"&amp\": \"and\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace unicode charetars\n",
    "for pattern_string, char in regex_html_tags.items():\n",
    "    congress[\"text\"] = congress[\"text\"].str.replace(pattern_string, char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress[\"text\"] = (congress[\"text\"]\n",
    "    .str.lower()\n",
    "    .str.replace(regex_links, \"\")\n",
    "    .str.replace(regex_whitespace, character_set[\"space\"])\n",
    "    .str.replace(regex_unknown, '')\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress.to_pickle('../Data/Processed/congress_cleaned_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37964bitsocialgraphsprojectconda9e1414738f16463880d93a451ffa336f",
   "display_name": "Python 3.7.9 64-bit ('social_graphs_project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2d507ec087116654eb570fc9cf9c6e4e826fec4ad12e36592899183da9bc57da"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}